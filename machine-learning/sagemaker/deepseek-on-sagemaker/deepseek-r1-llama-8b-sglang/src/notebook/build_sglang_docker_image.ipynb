{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee7db79-a92b-4ddd-a750-3dc690594bab",
   "metadata": {},
   "source": [
    "# Prepare the SGLang SageMaker container\n",
    "\n",
    "â—This notebook works well on `ml.g5.xlarge` instance with 50GB of disk size and `PyTorch 2.2.0 Python 3.10 CPU optimized kernel` from **SageMaker Studio Classic** or `Python3 kernel` from **JupyterLab**.\n",
    "\n",
    "This notebook has been rewritten based on [sagemaker-genai-hosting-examples/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb](https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb)\n",
    "\n",
    "Note that SageMaker provides [pre-built SageMaker AI Docker images](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html) that can help you quickly start with the model inference on SageMaker. It also allows you to [bring your own Docker container](https://docs.aws.amazon.com/sagemaker/latest/dg/adapt-inference-container.html) and use it inside SageMaker AI for training and inference. To be compatible with SageMaker AI, your container must have the following characteristics:\n",
    "\n",
    "- Your container must have a web server listening on port `8080`.\n",
    "- Your container must accept POST requests to the `/invocations` and `/ping` real-time endpoints.\n",
    "\n",
    "In this notebook, we'll make a custom Docker container to adapt the [SGLang](https://github.com/sgl-project/sglang) framework to run on SageMaker AI endpoints. SGLang is a serving framework for large language models that provides state-of-the-art performance, including a fast backend runtime for efficient serving with RadixAttention, extensive model support, and an active open-source community. For more information refer to [https://docs.sglang.ai/index.html](https://docs.sglang.ai/index.html) and [https://github.com/sgl-project/sglang](https://github.com/sgl-project/sglang).\n",
    "\n",
    "By using the custom Docker container for SGLang, you can run advanced AI models like the [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) on a SageMaker AI endpoint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202a132-8b77-49c7-8ca3-82225b55e01f",
   "metadata": {},
   "source": [
    "### Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e47d1-02d4-4a8e-b0b7-3cd6a2dc6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "\n",
    "!pip install -U \"sagemaker>=2.237.1\"\n",
    "!pip install -U sagemaker-studio-image-build==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99147e8-3e70-46ae-aa0f-81c40c3f5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep -E -w \"sagemaker|sagemaker_studio_image_build\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cffc7c2-7007-483c-b6b1-04688f258e03",
   "metadata": {},
   "source": [
    "### Prepare the SGLang SageMaker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44982043-15c5-42cc-b979-8d0190782c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKER_IMAGE = \"sglang-sagemaker\"\n",
    "DOCKER_IMAGE_TAG = \"latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d5fad5-b7db-403e-831d-127483f3cbb3",
   "metadata": {},
   "source": [
    "[sm-docker](https://github.com/aws-samples/sagemaker-studio-image-build-cli) is a CLI for building Docker images in SageMaker Studio using AWS CodeBuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e8973b-aaea-4ab2-853e-e0cf107a5248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!cd ./container && sm-docker build . --repository {DOCKER_IMAGE}:{DOCKER_IMAGE_TAG} --build-arg BASE_IMAGE='lmsysorg/sglang:v0.4.4.post1-cu125'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf89324-5454-4f95-adba-261e16fbb05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "session = Session()\n",
    "region = session._region_name\n",
    "\n",
    "ecr_uri = f'{session.account_id()}.dkr.ecr.{region}.amazonaws.com/{DOCKER_IMAGE}:{DOCKER_IMAGE_TAG}'\n",
    "ecr_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5613d41-18bf-46b9-b401-a6d7a45c6ef6",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [sm-docker](https://github.com/aws-samples/sagemaker-studio-image-build-cli): a CLI for building Docker images in SageMaker Studio using AWS CodeBuild\n",
    "- [sagemaker-genai-hosting-examples/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb](https://github.com/aws-samples/sagemaker-genai-hosting-examples/blob/main/Deepseek/SGLang-Deepseek/deepseek-r1-llama-70b-sglang.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
